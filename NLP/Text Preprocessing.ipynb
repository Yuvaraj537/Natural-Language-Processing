{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3100efca-4752-4fbf-aac8-9412bdd8fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\yuvar\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6fe18c-bd2b-465a-adf0-42dab9ccb0cc",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9cc79fae-5484-491f-9eff-2fc92d7bcc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Hello Welcome , to Yuvaraj NLP Tutorials.\n",
    "Please to watch the entire course! to become expert in NLP.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c147065a-002c-4b6f-8772-afef5f935225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome , to Yuvaraj NLP Tutorials.\n",
      "Please to watch the entire course! to become expert in NLP.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8ee8b2b-89c6-4382-aa5b-59064c227dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization \n",
    "## sentence --> paragraph\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "616687b2-368f-4152-b18b-3b95a73f7328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e36b886e-7725-48d7-b6d0-97a614cd77c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Welcome , to Yuvaraj NLP Tutorials.',\n",
       " 'Please to watch the entire course!',\n",
       " 'to become expert in NLP.']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94eb12f7-a73e-4988-803d-0afaa8838fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f7fbef4d-ed2d-48df-bf74-b943395ca41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e82bb0b8-ad6e-4b46-b57d-92eae81eaccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome , to Yuvaraj NLP Tutorials.\n",
      "Please to watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eaa30c34-8fc9-4a74-a2e2-cf19b4106283",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization \n",
    "##  paragraph-->words\n",
    "## sentence--> words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97ce7b5e-3a9b-4312-9657-4862317595af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Yuvaraj',\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1cbd6e36-3f50-4868-ab9a-ae7cda28973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome , to Yuvaraj NLP Tutorials.\n",
      "Please to watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e44022de-4dcb-45a0-b977-966b4ca1a51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Welcome', ',', 'to', 'Yuvaraj', 'NLP', 'Tutorials', '.']\n",
      "['Please', 'to', 'watch', 'the', 'entire', 'course', '!']\n",
      "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b57b3cb7-dfed-4eaf-8c2d-12098819c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f9adabdd-5e1e-486d-a4f1-c240d726137a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Yuvaraj',\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f7560898-af53-41f8-8a46-9548e10e2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import  TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d321683a-e4f6-4b37-8e13-4ae05f57df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c5124f30-8dfc-4676-bc2d-cabd8430d1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Yuvaraj',\n",
       " 'NLP',\n",
       " 'Tutorials.',\n",
       " 'Please',\n",
       " 'to',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d3ea3a-049b-4573-b2ba-02391197811e",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554dbc8-5ee6-47df-8073-44214797405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classificatio problem\n",
    "## Comments of product is a positive review or negative review \n",
    "## Review--> eating,eat,eaten [going,gone,goes]-->go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c7e47bdf-be20-4d50-a9c5-ce8d89ce2902",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"write\",\"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61547bf0-3cda-4f2d-a17b-ce2691b0dbc7",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "05604ada-860e-4ebf-8e81-62ce26d6aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6b726c57-1577-40c2-b336-f0a81a56402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemming=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "badf605e-9b13-4f75-aa07-bb9c747b483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "write--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalize--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8b460d90-ddeb-4b34-b19a-d121e6ffe48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('Congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8d7d95c5-24df-4ea7-a430-41401608b115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sit'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"sitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e6db5b3d-e557-4bf3-94fd-e5e4d6055ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "90d82a1b-bf68-4f10-8f39-37913fea9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer = RegexpStemmer('ing$|s$|e$|able$',min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b9e52702-6145-4eff-a624-f15a69e7669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8e29ed95-af72-4095-bdec-8946e1f80a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingeat'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('ingeating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490ab341-a218-447a-b63e-5ec28b3f5007",
   "metadata": {},
   "source": [
    "# Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9e783869-453b-4fb9-ae8f-335d9c56514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f06baa31-0389-4573-ac32-71bbfbcef92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballstemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f6431ab7-66fb-4991-a1a1-f8bec57b9b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "write--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalize--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+snowballstemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cf317105-0183-4d8d-b88b-7662930b9189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('fairly'),stemming.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "109cb350-5f77-4762-9340-986ca956f4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('fairly'),snowballstemmer.stem('sportingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "dd5fba9b-cf0c-4ced-b310-4adb9eb3e025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballstemmer.stem('goes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5c92611a-2b17-42e3-982e-a861a89aa08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goe'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('goes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323421e-b7ea-4ae9-80af-007e343b4b2e",
   "metadata": {},
   "source": [
    "# Wordnet Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "33f42311-f105-46be-abf1-e383a3ddde3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q&A ,Chatbots, text summarization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c1fb3192-4b6c-446d-a49f-9a4cc14dc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6305ff75-60e9-46ce-9ffc-8c499dec074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yuvar\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ad3bf648-24a9-4d6f-84c5-3e696d2766ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS- NOUN-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\",pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "93248eb1-0b47-4927-b020-c57b096d2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"write\",\"programming\",\"programs\",\"history\",\"finally\",\"finalize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "5f2f272b-6359-4799-a2db-5963129cedeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eat\n",
      "writing--->write\n",
      "write--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->history\n",
      "finally--->finally\n",
      "finalize--->finalize\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+lemmatizer.lemmatize(word,pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7ac8d961-b998-4b77-bcc4-6b9a9a4d32f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"goes\", pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6866f44e-e800-4d88-bc95-0f3b313436e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairly', 'Sportingly')"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"fairly\", pos='v'),lemmatizer.lemmatize(\"Sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee3b6f-f38a-42ae-9897-e67a807eb8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
